2023-01-18 13:54:23,184 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 20000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 2
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 4
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.3
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.3
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = trash
init_wandb.id = trash000
2023-01-18 13:54:23,187 - __main__ - INFO - Creating model...
2023-01-18 13:54:23,249 - __main__ - INFO - Using device: cpu
2023-01-18 13:54:23,249 - __main__ - INFO - Loading data...
2023-01-18 13:54:23,249 - __main__ - INFO - Training for maximum of 200 epochs...
2023-01-18 13:54:23,250 - __main__ - INFO - Loading data
2023-01-18 13:54:24,061 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-18 13:54:24,061 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-18 13:54:24,110 - __main__ - WARNING - Exception while running batch: size mismatch, m1: [4608 x 160], m2: [288 x 8] at ../aten/src/TH/generic/THTensorMath.cpp:197
2023-01-18 13:55:48,903 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 20000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 2
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 4
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.3
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.3
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = trash
init_wandb.id = trash000
2023-01-18 13:55:48,905 - __main__ - INFO - Creating model...
2023-01-18 13:55:48,976 - __main__ - INFO - Using device: cpu
2023-01-18 13:55:48,976 - __main__ - INFO - Loading data...
2023-01-18 13:55:48,976 - __main__ - INFO - Training for maximum of 200 epochs...
2023-01-18 13:55:48,977 - __main__ - INFO - Loading data
2023-01-18 13:55:49,695 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-18 13:55:49,695 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-18 13:59:52,138 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 20000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 2
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 512
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 4
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.3
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.3
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 64
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = trash
init_wandb.id = trash000
2023-01-18 13:59:52,140 - __main__ - INFO - Creating model...
2023-01-18 13:59:52,168 - __main__ - INFO - Using device: cpu
2023-01-18 13:59:52,168 - __main__ - INFO - Loading data...
2023-01-18 13:59:52,168 - __main__ - INFO - Training for maximum of 200 epochs...
2023-01-18 13:59:52,169 - __main__ - INFO - Loading data
2023-01-18 13:59:52,893 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-18 13:59:52,894 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-18 14:00:29,766 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 20000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 2
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 512
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 4
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.3
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.3
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = trash
init_wandb.id = trash000
2023-01-18 14:00:29,767 - __main__ - INFO - Creating model...
2023-01-18 14:00:29,798 - __main__ - INFO - Using device: cpu
2023-01-18 14:00:29,799 - __main__ - INFO - Loading data...
2023-01-18 14:00:29,799 - __main__ - INFO - Training for maximum of 200 epochs...
2023-01-18 14:00:29,799 - __main__ - INFO - Loading data
2023-01-18 14:00:30,595 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-18 14:00:30,595 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-18 14:02:09,653 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 20000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 2
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 512
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 6
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.3
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.3
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = trash
init_wandb.id = trash000
2023-01-18 14:02:09,655 - __main__ - INFO - Creating model...
2023-01-18 14:02:09,694 - __main__ - INFO - Using device: cpu
2023-01-18 14:02:09,694 - __main__ - INFO - Loading data...
2023-01-18 14:02:09,695 - __main__ - INFO - Training for maximum of 200 epochs...
2023-01-18 14:02:09,696 - __main__ - INFO - Loading data
2023-01-18 14:02:10,415 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-18 14:02:10,415 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-18 21:14:45,327 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 20000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 2
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 512
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 6
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = trash
init_wandb.id = trash000
2023-01-18 21:14:45,330 - __main__ - INFO - Creating model...
2023-01-18 21:14:45,368 - __main__ - INFO - Using device: cpu
2023-01-18 21:14:45,368 - __main__ - INFO - Loading data...
2023-01-18 21:14:45,368 - __main__ - INFO - Training for maximum of 200 epochs...
2023-01-18 21:14:45,369 - __main__ - INFO - Loading data
2023-01-18 21:14:46,116 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-18 21:14:46,116 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-18 21:15:10,433 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 20000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 2
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 512
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 6
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.3
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.3
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = trash
init_wandb.id = trash000
2023-01-18 21:15:10,435 - __main__ - INFO - Creating model...
2023-01-18 21:15:10,476 - __main__ - INFO - Using device: cpu
2023-01-18 21:15:10,476 - __main__ - INFO - Loading data...
2023-01-18 21:15:10,476 - __main__ - INFO - Training for maximum of 200 epochs...
2023-01-18 21:15:10,477 - __main__ - INFO - Loading data
2023-01-18 21:15:11,311 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-18 21:15:11,311 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-18 21:16:13,949 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 20000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 2
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 6
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.3
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.3
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = trash
init_wandb.id = trash000
2023-01-18 21:16:13,951 - __main__ - INFO - Creating model...
2023-01-18 21:16:14,040 - __main__ - INFO - Using device: cpu
2023-01-18 21:16:14,040 - __main__ - INFO - Loading data...
2023-01-18 21:16:14,041 - __main__ - INFO - Training for maximum of 200 epochs...
2023-01-18 21:16:14,041 - __main__ - INFO - Loading data
2023-01-18 21:16:14,800 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-18 21:16:14,800 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-18 21:16:48,052 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 20000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 2
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 768
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 6
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.3
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.3
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = trash
init_wandb.id = trash000
2023-01-18 21:16:48,055 - __main__ - INFO - Creating model...
2023-01-18 21:16:48,117 - __main__ - INFO - Using device: cpu
2023-01-18 21:16:48,118 - __main__ - INFO - Loading data...
2023-01-18 21:16:48,118 - __main__ - INFO - Training for maximum of 200 epochs...
2023-01-18 21:16:48,118 - __main__ - INFO - Loading data
2023-01-18 21:16:48,899 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-18 21:16:48,899 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
