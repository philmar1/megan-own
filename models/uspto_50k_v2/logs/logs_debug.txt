2023-01-07 13:08:09,207 - root - DEBUG - Logging configured!
2023-01-07 13:08:09,207 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 20000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 4
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 6
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.0
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.0
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = v2
init_wandb.id = megan0v2
2023-01-07 13:08:09,222 - __main__ - INFO - Creating model...
2023-01-07 13:08:10,459 - __main__ - INFO - Using device: cuda:0
2023-01-07 13:08:10,569 - git.util - DEBUG - Failed checking if running in CYGWIN due to: FileNotFoundError(2, 'Le fichier spécifié est introuvable', None, 2, None)
2023-01-07 13:08:10,571 - git.cmd - DEBUG - Popen(['git', 'rev-parse', '--show-toplevel'], cwd=C:\Users\Marie\Documents\PhilTheBeast\Projets_IA\megan-own, universal_newlines=False, shell=None, istream=None)
2023-01-07 13:08:12,095 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2023-01-07 13:08:13,462 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 568
2023-01-07 13:08:13,467 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2023-01-07 13:08:13,634 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 339
2023-01-07 13:08:13,659 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=C:\Users\Marie\Documents\PhilTheBeast\Projets_IA\megan-own, universal_newlines=False, shell=None, istream=<valid stream>)
2023-01-07 13:09:14,348 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): o151352.ingest.sentry.io:443
2023-01-07 13:09:14,428 - urllib3.connectionpool - DEBUG - https://o151352.ingest.sentry.io:443 "POST /api/5288891/store/ HTTP/1.1" 200 41
2023-01-07 13:18:28,145 - root - DEBUG - Logging configured!
2023-01-07 13:18:28,146 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 20000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 4
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 6
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.0
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.0
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = v2
init_wandb.id = megan1v2
2023-01-07 13:18:28,152 - __main__ - INFO - Creating model...
2023-01-07 13:18:29,377 - __main__ - INFO - Using device: cuda:0
2023-01-07 13:18:29,484 - git.util - DEBUG - Failed checking if running in CYGWIN due to: FileNotFoundError(2, 'Le fichier spécifié est introuvable', None, 2, None)
2023-01-07 13:18:29,486 - git.cmd - DEBUG - Popen(['git', 'rev-parse', '--show-toplevel'], cwd=C:\Users\Marie\Documents\PhilTheBeast\Projets_IA\megan-own, universal_newlines=False, shell=None, istream=None)
2023-01-07 13:18:30,983 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2023-01-07 13:18:32,195 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 568
2023-01-07 13:18:32,198 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2023-01-07 13:18:32,371 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 339
2023-01-07 13:18:32,394 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=C:\Users\Marie\Documents\PhilTheBeast\Projets_IA\megan-own, universal_newlines=False, shell=None, istream=<valid stream>)
2023-01-07 13:18:38,790 - __main__ - INFO - Loading data...
2023-01-07 13:18:38,790 - __main__ - INFO - Training for maximum of 200 epochs...
2023-01-07 13:18:38,791 - __main__ - INFO - Loading data
2023-01-07 13:18:39,648 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-07 13:18:39,649 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-07 13:19:00,761 - __main__ - WARNING - Exception while running batch: CUDA out of memory. Tried to allocate 222.00 MiB (GPU 0; 6.00 GiB total capacity; 5.24 GiB already allocated; 0 bytes free; 56.64 MiB cached)
2023-01-07 13:20:20,338 - root - DEBUG - Logging configured!
2023-01-07 13:20:20,338 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 20000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 4
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 6
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.0
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.0
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = v2
init_wandb.id = megan1v2
2023-01-07 13:20:20,345 - __main__ - INFO - Creating model...
2023-01-07 13:20:21,566 - __main__ - INFO - Using device: cuda:0
2023-01-07 13:20:21,672 - git.util - DEBUG - Failed checking if running in CYGWIN due to: FileNotFoundError(2, 'Le fichier spécifié est introuvable', None, 2, None)
2023-01-07 13:20:21,673 - git.cmd - DEBUG - Popen(['git', 'rev-parse', '--show-toplevel'], cwd=C:\Users\Marie\Documents\PhilTheBeast\Projets_IA\megan-own, universal_newlines=False, shell=None, istream=None)
2023-01-07 13:20:23,184 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2023-01-07 13:20:24,521 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 568
2023-01-07 13:20:24,528 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2023-01-07 13:20:24,689 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 339
2023-01-07 13:20:24,713 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=C:\Users\Marie\Documents\PhilTheBeast\Projets_IA\megan-own, universal_newlines=False, shell=None, istream=<valid stream>)
2023-01-07 13:20:25,885 - __main__ - INFO - Loading data...
2023-01-07 13:20:25,886 - __main__ - INFO - Training for maximum of 200 epochs...
2023-01-07 13:20:25,887 - __main__ - INFO - Loading data
2023-01-07 13:20:26,733 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-07 13:20:26,734 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-07 13:20:46,837 - __main__ - WARNING - Exception while running batch: CUDA out of memory. Tried to allocate 222.00 MiB (GPU 0; 6.00 GiB total capacity; 5.24 GiB already allocated; 0 bytes free; 56.64 MiB cached)
2023-01-07 13:25:03,777 - root - DEBUG - Logging configured!
2023-01-07 13:25:03,777 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 20000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 4
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 6
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.0
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.0
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = v2
init_wandb.id = megan1v2
2023-01-07 13:25:03,784 - __main__ - INFO - Creating model...
2023-01-07 13:25:04,999 - __main__ - INFO - Using device: cuda:0
2023-01-07 13:25:05,107 - git.util - DEBUG - Failed checking if running in CYGWIN due to: FileNotFoundError(2, 'Le fichier spécifié est introuvable', None, 2, None)
2023-01-07 13:25:05,109 - git.cmd - DEBUG - Popen(['git', 'rev-parse', '--show-toplevel'], cwd=C:\Users\Marie\Documents\PhilTheBeast\Projets_IA\megan-own, universal_newlines=False, shell=None, istream=None)
2023-01-07 13:25:06,611 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2023-01-07 13:25:08,017 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 568
2023-01-07 13:25:08,024 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2023-01-07 13:25:08,183 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 339
2023-01-07 13:25:08,204 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=C:\Users\Marie\Documents\PhilTheBeast\Projets_IA\megan-own, universal_newlines=False, shell=None, istream=<valid stream>)
2023-01-07 13:25:09,443 - __main__ - INFO - Loading data...
2023-01-07 13:25:09,444 - __main__ - INFO - Training for maximum of 200 epochs...
2023-01-07 13:25:09,445 - __main__ - INFO - Loading data
2023-01-07 13:25:10,290 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-07 13:25:10,291 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-07 13:25:30,217 - __main__ - WARNING - Exception while running batch: CUDA out of memory. Tried to allocate 222.00 MiB (GPU 0; 6.00 GiB total capacity; 5.24 GiB already allocated; 0 bytes free; 56.64 MiB cached)
2023-01-07 13:27:45,883 - root - DEBUG - Logging configured!
2023-01-07 13:27:45,883 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 20000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 4
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 4
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.3
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.0
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = v2
init_wandb.id = megan1v2
2023-01-07 13:27:45,890 - __main__ - INFO - Creating model...
2023-01-07 13:27:47,093 - __main__ - INFO - Using device: cuda:0
2023-01-07 13:27:47,197 - git.util - DEBUG - Failed checking if running in CYGWIN due to: FileNotFoundError(2, 'Le fichier spécifié est introuvable', None, 2, None)
2023-01-07 13:27:47,199 - git.cmd - DEBUG - Popen(['git', 'rev-parse', '--show-toplevel'], cwd=C:\Users\Marie\Documents\PhilTheBeast\Projets_IA\megan-own, universal_newlines=False, shell=None, istream=None)
2023-01-07 13:27:48,728 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2023-01-07 13:27:49,939 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 568
2023-01-07 13:27:49,946 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2023-01-07 13:27:50,113 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 339
2023-01-07 13:27:50,141 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=C:\Users\Marie\Documents\PhilTheBeast\Projets_IA\megan-own, universal_newlines=False, shell=None, istream=<valid stream>)
2023-01-07 13:27:51,358 - __main__ - INFO - Loading data...
2023-01-07 13:27:51,359 - __main__ - INFO - Training for maximum of 200 epochs...
2023-01-07 13:27:51,360 - __main__ - INFO - Loading data
2023-01-07 13:27:52,219 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-07 13:27:52,219 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-07 13:28:10,327 - __main__ - WARNING - Exception while running batch: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 6.00 GiB total capacity; 5.27 GiB already allocated; 0 bytes free; 32.00 MiB cached)
2023-01-07 13:31:21,650 - root - DEBUG - Logging configured!
2023-01-07 13:31:21,650 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 20000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 3
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 6
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.0
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = v2
init_wandb.id = megan1v2
2023-01-07 13:31:21,656 - __main__ - INFO - Creating model...
2023-01-07 13:31:22,882 - __main__ - INFO - Using device: cuda:0
2023-01-07 13:31:22,990 - git.util - DEBUG - Failed checking if running in CYGWIN due to: FileNotFoundError(2, 'Le fichier spécifié est introuvable', None, 2, None)
2023-01-07 13:31:22,992 - git.cmd - DEBUG - Popen(['git', 'rev-parse', '--show-toplevel'], cwd=C:\Users\Marie\Documents\PhilTheBeast\Projets_IA\megan-own, universal_newlines=False, shell=None, istream=None)
2023-01-07 13:31:24,499 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2023-01-07 13:31:25,858 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 568
2023-01-07 13:31:25,862 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2023-01-07 13:31:26,004 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 339
2023-01-07 13:31:26,025 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=C:\Users\Marie\Documents\PhilTheBeast\Projets_IA\megan-own, universal_newlines=False, shell=None, istream=<valid stream>)
2023-01-07 13:31:27,304 - __main__ - INFO - Loading data...
2023-01-07 13:31:27,305 - __main__ - INFO - Training for maximum of 200 epochs...
2023-01-07 13:31:27,306 - __main__ - INFO - Loading data
2023-01-07 13:31:28,164 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-07 13:31:28,165 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-07 13:31:45,892 - __main__ - WARNING - Exception while running batch: CUDA out of memory. Tried to allocate 166.00 MiB (GPU 0; 6.00 GiB total capacity; 5.16 GiB already allocated; 0 bytes free; 101.35 MiB cached)
2023-01-07 13:33:02,710 - root - DEBUG - Logging configured!
2023-01-07 13:33:02,712 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 20000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 3
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 4
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.0
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = v2
init_wandb.id = megan1v2
2023-01-07 13:33:02,717 - __main__ - INFO - Creating model...
2023-01-07 13:33:03,925 - __main__ - INFO - Using device: cuda:0
2023-01-07 13:33:04,033 - git.util - DEBUG - Failed checking if running in CYGWIN due to: FileNotFoundError(2, 'Le fichier spécifié est introuvable', None, 2, None)
2023-01-07 13:33:04,035 - git.cmd - DEBUG - Popen(['git', 'rev-parse', '--show-toplevel'], cwd=C:\Users\Marie\Documents\PhilTheBeast\Projets_IA\megan-own, universal_newlines=False, shell=None, istream=None)
2023-01-07 13:33:05,545 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2023-01-07 13:33:06,870 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 568
2023-01-07 13:33:06,873 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2023-01-07 13:33:07,032 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 339
2023-01-07 13:33:07,060 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=C:\Users\Marie\Documents\PhilTheBeast\Projets_IA\megan-own, universal_newlines=False, shell=None, istream=<valid stream>)
2023-01-07 13:33:08,289 - __main__ - INFO - Loading data...
2023-01-07 13:33:08,290 - __main__ - INFO - Training for maximum of 200 epochs...
2023-01-07 13:33:08,291 - __main__ - INFO - Loading data
2023-01-07 13:33:09,139 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-07 13:33:09,140 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-07 13:33:36,064 - __main__ - WARNING - Exception while running batch: CUDA out of memory. Tried to allocate 126.00 MiB (GPU 0; 6.00 GiB total capacity; 4.55 GiB already allocated; 0 bytes free; 668.46 MiB cached)
2023-01-07 22:11:48,445 - root - DEBUG - Logging configured!
2023-01-07 22:11:48,445 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 20000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 3
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 4
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.0
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = v2
init_wandb.id = megan1v2
2023-01-07 22:11:48,454 - __main__ - INFO - Creating model...
2023-01-07 22:11:50,207 - __main__ - INFO - Using device: cuda:0
2023-01-07 22:11:50,313 - git.util - DEBUG - Failed checking if running in CYGWIN due to: FileNotFoundError(2, 'Le fichier spécifié est introuvable', None, 2, None)
2023-01-07 22:11:50,315 - git.cmd - DEBUG - Popen(['git', 'rev-parse', '--show-toplevel'], cwd=C:\Users\Marie\Documents\PhilTheBeast\Projets_IA\megan-own, universal_newlines=False, shell=None, istream=None)
2023-01-07 22:11:51,817 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2023-01-07 22:11:53,186 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 568
2023-01-07 22:11:53,204 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2023-01-07 22:11:53,370 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 339
2023-01-07 22:11:53,394 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=C:\Users\Marie\Documents\PhilTheBeast\Projets_IA\megan-own, universal_newlines=False, shell=None, istream=<valid stream>)
2023-01-07 22:11:54,635 - __main__ - INFO - Loading data...
2023-01-07 22:11:54,635 - __main__ - INFO - Training for maximum of 200 epochs...
2023-01-07 22:11:54,636 - __main__ - INFO - Loading data
2023-01-07 22:11:55,492 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-07 22:11:55,493 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-07 22:12:22,277 - __main__ - WARNING - Exception while running batch: CUDA out of memory. Tried to allocate 126.00 MiB (GPU 0; 6.00 GiB total capacity; 4.55 GiB already allocated; 0 bytes free; 668.46 MiB cached)
2023-01-07 22:15:02,564 - root - DEBUG - Logging configured!
2023-01-07 22:15:02,564 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 20000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 3
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 4
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.3
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.3
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = v2
init_wandb.id = megan1v2
2023-01-07 22:15:02,571 - __main__ - INFO - Creating model...
2023-01-07 22:15:03,762 - __main__ - INFO - Using device: cuda:0
2023-01-07 22:15:03,871 - git.util - DEBUG - Failed checking if running in CYGWIN due to: FileNotFoundError(2, 'Le fichier spécifié est introuvable', None, 2, None)
2023-01-07 22:15:03,873 - git.cmd - DEBUG - Popen(['git', 'rev-parse', '--show-toplevel'], cwd=C:\Users\Marie\Documents\PhilTheBeast\Projets_IA\megan-own, universal_newlines=False, shell=None, istream=None)
2023-01-07 22:15:05,396 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2023-01-07 22:15:06,708 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 568
2023-01-07 22:15:06,720 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2023-01-07 22:15:06,872 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 339
2023-01-07 22:15:06,895 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=C:\Users\Marie\Documents\PhilTheBeast\Projets_IA\megan-own, universal_newlines=False, shell=None, istream=<valid stream>)
2023-01-07 22:15:08,136 - __main__ - INFO - Loading data...
2023-01-07 22:15:08,136 - __main__ - INFO - Training for maximum of 200 epochs...
2023-01-07 22:15:08,137 - __main__ - INFO - Loading data
2023-01-07 22:15:08,981 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-07 22:15:08,981 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-07 22:15:35,494 - __main__ - WARNING - Exception while running batch: CUDA out of memory. Tried to allocate 126.00 MiB (GPU 0; 6.00 GiB total capacity; 4.74 GiB already allocated; 0 bytes free; 583.09 MiB cached)
2023-01-10 11:08:08,221 - root - DEBUG - Logging configured!
2023-01-10 11:08:08,222 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 20000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 3
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 4
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.3
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.3
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = v2
init_wandb.id = megan1v2
2023-01-10 11:08:08,229 - __main__ - INFO - Creating model...
2023-01-10 11:08:09,996 - __main__ - INFO - Using device: cuda:0
2023-01-10 11:11:34,106 - root - DEBUG - Logging configured!
2023-01-10 11:11:34,106 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 20000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 3
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 4
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.3
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.3
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = v2
init_wandb.id = megan1v2
2023-01-10 11:11:34,113 - __main__ - INFO - Creating model...
2023-01-10 11:11:35,315 - __main__ - INFO - Using device: cuda:0
2023-01-10 11:12:13,324 - root - DEBUG - Logging configured!
2023-01-10 11:12:13,324 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 20000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 3
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 4
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.3
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.3
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = v2
init_wandb.id = megan1v2
2023-01-10 11:12:13,331 - __main__ - INFO - Creating model...
2023-01-10 11:12:14,526 - __main__ - INFO - Using device: cuda:0
2023-01-10 11:12:14,580 - src.utils.dispatch_utils - INFO - 38234.5 Kb
2023-01-10 11:12:14,686 - git.util - DEBUG - Failed checking if running in CYGWIN due to: FileNotFoundError(2, 'Le fichier spécifié est introuvable', None, 2, None)
2023-01-10 11:12:14,688 - git.cmd - DEBUG - Popen(['git', 'rev-parse', '--show-toplevel'], cwd=C:\Users\Marie\Documents\PhilTheBeast\Projets_IA\megan-own, universal_newlines=False, shell=None, istream=None)
2023-01-10 11:12:16,215 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2023-01-10 11:12:17,618 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 568
2023-01-10 11:12:17,631 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2023-01-10 11:12:17,796 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 339
2023-01-10 11:12:17,840 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=C:\Users\Marie\Documents\PhilTheBeast\Projets_IA\megan-own, universal_newlines=False, shell=None, istream=<valid stream>)
2023-01-10 11:12:20,718 - __main__ - INFO - Loading data...
2023-01-10 11:12:20,719 - __main__ - INFO - Training for maximum of 200 epochs...
2023-01-10 11:12:20,720 - __main__ - INFO - Loading data
2023-01-10 11:12:21,584 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-10 11:12:21,584 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-10 11:12:49,400 - __main__ - WARNING - Exception while running batch: CUDA out of memory. Tried to allocate 126.00 MiB (GPU 0; 6.00 GiB total capacity; 4.74 GiB already allocated; 0 bytes free; 583.09 MiB cached)
2023-01-10 11:25:09,958 - root - DEBUG - Logging configured!
2023-01-10 11:25:09,959 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 20000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 3
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 4
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.3
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.3
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = v2
init_wandb.id = megan1v2
2023-01-10 11:25:09,965 - __main__ - INFO - Creating model...
2023-01-10 11:25:11,146 - __main__ - INFO - Using device: cuda:0
2023-01-10 11:25:11,197 - src.utils.dispatch_utils - INFO - 38234.5 Kb
2023-01-10 11:25:11,303 - git.util - DEBUG - Failed checking if running in CYGWIN due to: FileNotFoundError(2, 'Le fichier spécifié est introuvable', None, 2, None)
2023-01-10 11:25:11,305 - git.cmd - DEBUG - Popen(['git', 'rev-parse', '--show-toplevel'], cwd=C:\Users\Marie\Documents\PhilTheBeast\Projets_IA\megan-own, universal_newlines=False, shell=None, istream=None)
2023-01-10 11:25:12,813 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2023-01-10 11:25:14,145 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 568
2023-01-10 11:25:14,159 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2023-01-10 11:25:14,327 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 339
2023-01-10 11:25:14,359 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=C:\Users\Marie\Documents\PhilTheBeast\Projets_IA\megan-own, universal_newlines=False, shell=None, istream=<valid stream>)
2023-01-10 11:25:15,742 - __main__ - INFO - Loading data...
2023-01-10 11:25:15,742 - __main__ - INFO - Training for maximum of 200 epochs...
2023-01-10 11:25:15,743 - __main__ - INFO - Loading data
2023-01-10 11:25:16,581 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-10 11:25:16,582 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-10 11:25:43,600 - __main__ - WARNING - Exception while running batch: CUDA out of memory. Tried to allocate 126.00 MiB (GPU 0; 6.00 GiB total capacity; 4.74 GiB already allocated; 0 bytes free; 583.09 MiB cached)
2023-01-10 11:34:31,749 - root - DEBUG - Logging configured!
2023-01-10 11:34:31,750 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 20000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 2
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 6
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.3
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.3
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = v2
init_wandb.id = megan1v2
2023-01-10 11:34:31,756 - __main__ - INFO - Creating model...
2023-01-10 11:34:32,971 - __main__ - INFO - Using device: cuda:0
2023-01-10 11:34:33,025 - src.utils.dispatch_utils - INFO - 50551.5 Kb
2023-01-10 11:34:33,132 - git.util - DEBUG - Failed checking if running in CYGWIN due to: FileNotFoundError(2, 'Le fichier spécifié est introuvable', None, 2, None)
2023-01-10 11:34:33,134 - git.cmd - DEBUG - Popen(['git', 'rev-parse', '--show-toplevel'], cwd=C:\Users\Marie\Documents\PhilTheBeast\Projets_IA\megan-own, universal_newlines=False, shell=None, istream=None)
2023-01-10 11:34:34,634 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2023-01-10 11:34:35,993 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 568
2023-01-10 11:34:36,006 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2023-01-10 11:34:36,181 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 339
2023-01-10 11:34:36,211 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=C:\Users\Marie\Documents\PhilTheBeast\Projets_IA\megan-own, universal_newlines=False, shell=None, istream=<valid stream>)
2023-01-10 11:34:37,447 - __main__ - INFO - Loading data...
2023-01-10 11:34:37,448 - __main__ - INFO - Training for maximum of 200 epochs...
2023-01-10 11:34:37,449 - __main__ - INFO - Loading data
2023-01-10 11:34:38,305 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-10 11:34:38,306 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-10 11:35:37,215 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): o151352.ingest.sentry.io:443
2023-01-10 11:35:37,291 - urllib3.connectionpool - DEBUG - https://o151352.ingest.sentry.io:443 "POST /api/5288891/envelope/ HTTP/1.1" 200 2
2023-01-10 11:53:55,472 - __main__ - WARNING - Exception while running batch: CUDA out of memory. Tried to allocate 98.00 MiB (GPU 0; 6.00 GiB total capacity; 5.18 GiB already allocated; 0 bytes free; 125.09 MiB cached)
2023-01-10 12:00:13,912 - root - DEBUG - Logging configured!
2023-01-10 12:00:13,912 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 20000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 2
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 4
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.3
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.3
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = v2
init_wandb.id = megan1v2
2023-01-10 12:00:13,919 - __main__ - INFO - Creating model...
2023-01-10 12:00:15,109 - __main__ - INFO - Using device: cuda:0
2023-01-10 12:00:15,163 - src.utils.dispatch_utils - INFO - 38234.5 Kb
2023-01-10 12:00:15,269 - git.util - DEBUG - Failed checking if running in CYGWIN due to: FileNotFoundError(2, 'Le fichier spécifié est introuvable', None, 2, None)
2023-01-10 12:00:15,270 - git.cmd - DEBUG - Popen(['git', 'rev-parse', '--show-toplevel'], cwd=C:\Users\Marie\Documents\PhilTheBeast\Projets_IA\megan-own, universal_newlines=False, shell=None, istream=None)
2023-01-10 12:00:16,764 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2023-01-10 12:00:18,185 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 568
2023-01-10 12:00:18,191 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2023-01-10 12:00:18,348 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 339
2023-01-10 12:00:18,391 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=C:\Users\Marie\Documents\PhilTheBeast\Projets_IA\megan-own, universal_newlines=False, shell=None, istream=<valid stream>)
2023-01-10 12:00:19,584 - __main__ - INFO - Loading data...
2023-01-10 12:00:19,585 - __main__ - INFO - Training for maximum of 200 epochs...
2023-01-10 12:00:19,586 - __main__ - INFO - Loading data
2023-01-10 12:00:20,433 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-10 12:00:20,434 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-10 12:01:19,356 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): o151352.ingest.sentry.io:443
2023-01-10 12:01:19,435 - urllib3.connectionpool - DEBUG - https://o151352.ingest.sentry.io:443 "POST /api/5288891/envelope/ HTTP/1.1" 200 2
2023-01-10 12:17:09,451 - __main__ - WARNING - Exception while running batch: CUDA out of memory. Tried to allocate 98.00 MiB (GPU 0; 6.00 GiB total capacity; 5.17 GiB already allocated; 0 bytes free; 91.03 MiB cached)
2023-01-10 19:42:42,689 - root - DEBUG - Logging configured!
2023-01-10 19:42:42,690 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 3
train_megan.train_samples_per_epoch = 1000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 2
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 4
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.3
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.3
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = trash
init_wandb.id = trash000
2023-01-10 19:42:42,696 - __main__ - INFO - Creating model...
2023-01-10 19:42:42,793 - __main__ - INFO - Using device: cpu
2023-01-10 19:44:45,885 - root - DEBUG - Logging configured!
2023-01-10 19:44:45,886 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 3
train_megan.train_samples_per_epoch = 1000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 2
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 4
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.3
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.3
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = trash
init_wandb.id = trash000
2023-01-10 19:44:45,888 - __main__ - INFO - Creating model...
2023-01-10 19:44:46,024 - __main__ - INFO - Using device: cpu
2023-01-10 19:44:46,154 - git.cmd - DEBUG - Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/Users/philippemartin/Documents/projets_IA/Drug Discovery/megan, universal_newlines=False, shell=None, istream=None)
2023-01-10 19:44:47,500 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2023-01-10 19:44:47,721 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 568
2023-01-10 19:44:47,739 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2023-01-10 19:44:47,966 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 339
2023-01-10 19:44:48,009 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/philippemartin/Documents/projets_IA/Drug Discovery/megan, universal_newlines=False, shell=None, istream=<valid stream>)
2023-01-10 19:44:53,398 - __main__ - INFO - Loading data...
2023-01-10 19:44:53,399 - __main__ - INFO - Training for maximum of 3 epochs...
2023-01-10 19:44:53,400 - __main__ - INFO - Loading data
2023-01-10 19:44:54,326 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-10 19:44:54,327 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-10 19:56:36,645 - root - DEBUG - Logging configured!
2023-01-10 19:56:36,646 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 3
train_megan.train_samples_per_epoch = 10000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 2
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 4
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.3
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.3
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = trash
init_wandb.id = trash000
2023-01-10 19:56:36,648 - __main__ - INFO - Creating model...
2023-01-10 19:56:36,719 - __main__ - INFO - Using device: cpu
2023-01-10 19:56:36,830 - git.cmd - DEBUG - Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/Users/philippemartin/Documents/projets_IA/Drug Discovery/megan, universal_newlines=False, shell=None, istream=None)
2023-01-10 19:56:38,262 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2023-01-10 19:56:38,479 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 568
2023-01-10 19:56:38,485 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2023-01-10 19:56:38,785 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 339
2023-01-10 19:56:38,815 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/philippemartin/Documents/projets_IA/Drug Discovery/megan, universal_newlines=False, shell=None, istream=<valid stream>)
2023-01-10 19:56:39,838 - __main__ - INFO - Loading data...
2023-01-10 19:56:39,839 - __main__ - INFO - Training for maximum of 3 epochs...
2023-01-10 19:56:39,840 - __main__ - INFO - Loading data
2023-01-10 19:56:40,644 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-10 19:56:40,644 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-10 20:14:53,500 - root - DEBUG - Logging configured!
2023-01-10 20:14:53,501 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 20000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 2
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 4
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.3
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.3
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = trash
init_wandb.id = trash000
2023-01-10 20:14:53,507 - __main__ - INFO - Creating model...
2023-01-10 20:14:53,587 - __main__ - INFO - Using device: cpu
2023-01-10 20:14:54,083 - git.cmd - DEBUG - Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/Users/philippemartin/Documents/projets_IA/Drug Discovery/megan, universal_newlines=False, shell=None, istream=None)
2023-01-10 20:14:56,463 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2023-01-10 20:14:56,660 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 568
2023-01-10 20:14:56,681 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2023-01-10 20:14:56,861 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 339
2023-01-10 20:14:56,930 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/philippemartin/Documents/projets_IA/Drug Discovery/megan, universal_newlines=False, shell=None, istream=<valid stream>)
2023-01-10 20:14:57,954 - __main__ - INFO - Loading data...
2023-01-10 20:14:57,954 - __main__ - INFO - Training for maximum of 200 epochs...
2023-01-10 20:14:57,957 - __main__ - INFO - Loading data
2023-01-10 20:14:58,818 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-10 20:14:58,818 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-10 20:14:59,036 - matplotlib.pyplot - DEBUG - Loaded backend macosx version unknown.
2023-01-10 20:14:59,036 - matplotlib.pyplot - DEBUG - Loaded backend MacOSX version unknown.
2023-01-10 20:14:59,039 - matplotlib.pyplot - DEBUG - Loaded backend macosx version unknown.
2023-01-13 15:43:49,123 - root - DEBUG - Logging configured!
2023-01-13 15:43:49,124 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 20000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 2
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 4
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.3
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.3
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = trash
init_wandb.id = trash000
2023-01-13 15:43:49,344 - matplotlib.pyplot - DEBUG - Loaded backend macosx version unknown.
2023-01-13 15:43:49,345 - matplotlib.pyplot - DEBUG - Loaded backend MacOSX version unknown.
2023-01-13 15:43:49,347 - matplotlib.pyplot - DEBUG - Loaded backend macosx version unknown.
2023-01-13 15:49:02,615 - root - DEBUG - Logging configured!
2023-01-13 15:49:02,617 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 10000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 2
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 4
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.3
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.3
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = trash
init_wandb.id = trash000
2023-01-13 15:49:02,770 - matplotlib.pyplot - DEBUG - Loaded backend macosx version unknown.
2023-01-13 15:49:02,770 - matplotlib.pyplot - DEBUG - Loaded backend MacOSX version unknown.
2023-01-13 15:49:02,772 - matplotlib.pyplot - DEBUG - Loaded backend macosx version unknown.
2023-01-13 15:54:55,230 - __main__ - INFO - Creating model...
2023-01-13 15:56:55,134 - __main__ - INFO - Using device: cpu
2023-01-13 15:56:55,665 - git.cmd - DEBUG - Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/Users/philippemartin/Documents/projets_IA/Drug Discovery/megan, universal_newlines=False, shell=None, istream=None)
2023-01-13 15:57:00,006 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2023-01-13 15:57:00,504 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 579
2023-01-13 15:57:00,540 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2023-01-13 15:57:01,010 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 339
2023-01-13 15:57:01,092 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/philippemartin/Documents/projets_IA/Drug Discovery/megan, universal_newlines=False, shell=None, istream=<valid stream>)
2023-01-13 15:57:02,918 - __main__ - INFO - Loading data...
2023-01-13 15:57:02,919 - __main__ - INFO - Training for maximum of 200 epochs...
2023-01-13 15:57:02,922 - __main__ - INFO - Loading data
2023-01-13 15:58:02,451 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): o151352.ingest.sentry.io:443
2023-01-13 15:58:02,758 - urllib3.connectionpool - DEBUG - https://o151352.ingest.sentry.io:443 "POST /api/5288891/envelope/ HTTP/1.1" 200 2
2023-01-13 16:09:31,538 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-13 16:09:31,539 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-13 16:37:02,808 - root - DEBUG - Logging configured!
2023-01-13 16:37:02,810 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 10000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 2
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 4
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.3
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.3
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = trash
init_wandb.id = trash000
2023-01-13 16:37:02,964 - matplotlib.pyplot - DEBUG - Loaded backend macosx version unknown.
2023-01-13 16:37:02,964 - matplotlib.pyplot - DEBUG - Loaded backend MacOSX version unknown.
2023-01-13 16:37:02,967 - matplotlib.pyplot - DEBUG - Loaded backend macosx version unknown.
2023-01-13 16:37:05,735 - __main__ - INFO - Creating model...
2023-01-13 16:37:08,027 - __main__ - INFO - Using device: cpu
2023-01-13 16:37:08,574 - git.cmd - DEBUG - Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/Users/philippemartin/Documents/projets_IA/Drug Discovery/megan, universal_newlines=False, shell=None, istream=None)
2023-01-13 16:37:11,141 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2023-01-13 16:37:11,629 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 579
2023-01-13 16:37:11,651 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2023-01-13 16:37:12,004 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 339
2023-01-13 16:37:12,071 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/philippemartin/Documents/projets_IA/Drug Discovery/megan, universal_newlines=False, shell=None, istream=<valid stream>)
2023-01-13 16:37:13,844 - __main__ - INFO - Loading data...
2023-01-13 16:37:13,844 - __main__ - INFO - Training for maximum of 200 epochs...
2023-01-13 16:37:13,849 - __main__ - INFO - Loading data
2023-01-13 16:38:13,519 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): o151352.ingest.sentry.io:443
2023-01-13 16:38:13,731 - urllib3.connectionpool - DEBUG - https://o151352.ingest.sentry.io:443 "POST /api/5288891/envelope/ HTTP/1.1" 200 2
2023-01-13 16:57:48,287 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-13 16:57:48,288 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-13 17:57:24,545 - root - DEBUG - Logging configured!
2023-01-13 17:57:24,546 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 10000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 2
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 4
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.3
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.3
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = trash
init_wandb.id = trash000
2023-01-13 17:57:24,553 - __main__ - INFO - Creating model...
2023-01-13 17:57:24,634 - __main__ - INFO - Using device: cpu
2023-01-13 17:57:25,167 - git.cmd - DEBUG - Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/Users/philippemartin/Documents/projets_IA/Drug Discovery/megan, universal_newlines=False, shell=None, istream=None)
2023-01-13 17:57:27,521 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2023-01-13 17:57:27,711 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 579
2023-01-13 17:57:27,733 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2023-01-13 17:57:27,912 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 339
2023-01-13 17:57:27,984 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/philippemartin/Documents/projets_IA/Drug Discovery/megan, universal_newlines=False, shell=None, istream=<valid stream>)
2023-01-13 17:57:29,109 - __main__ - INFO - Loading data...
2023-01-13 17:57:29,110 - __main__ - INFO - Training for maximum of 200 epochs...
2023-01-13 17:57:29,113 - __main__ - INFO - Loading data
2023-01-13 17:57:30,060 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-13 17:57:30,061 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-13 17:57:31,832 - matplotlib.pyplot - DEBUG - Loaded backend macosx version unknown.
2023-01-13 17:57:31,832 - matplotlib.pyplot - DEBUG - Loaded backend MacOSX version unknown.
2023-01-13 17:57:31,834 - matplotlib.pyplot - DEBUG - Loaded backend macosx version unknown.
2023-01-13 17:58:28,798 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): o151352.ingest.sentry.io:443
2023-01-13 17:58:28,901 - urllib3.connectionpool - DEBUG - https://o151352.ingest.sentry.io:443 "POST /api/5288891/envelope/ HTTP/1.1" 200 2
2023-01-13 18:18:24,472 - root - DEBUG - Logging configured!
2023-01-13 18:18:24,473 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 20000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 2
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 4
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.3
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.3
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = trash
init_wandb.id = trash000
2023-01-13 18:18:24,478 - __main__ - INFO - Creating model...
2023-01-13 18:18:24,561 - __main__ - INFO - Using device: cpu
2023-01-13 18:18:24,673 - git.cmd - DEBUG - Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/Users/philippemartin/Documents/projets_IA/Drug Discovery/megan, universal_newlines=False, shell=None, istream=None)
2023-01-13 18:18:25,789 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2023-01-13 18:18:26,013 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 579
2023-01-13 18:18:26,024 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2023-01-13 18:18:26,184 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 339
2023-01-13 18:18:26,224 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/philippemartin/Documents/projets_IA/Drug Discovery/megan, universal_newlines=False, shell=None, istream=<valid stream>)
2023-01-13 18:18:30,149 - __main__ - INFO - Loading data...
2023-01-13 18:18:30,150 - __main__ - INFO - Training for maximum of 200 epochs...
2023-01-13 18:18:30,151 - __main__ - INFO - Loading data
2023-01-13 18:18:31,073 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-13 18:18:31,074 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-13 18:19:29,979 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): o151352.ingest.sentry.io:443
2023-01-13 18:19:30,048 - urllib3.connectionpool - DEBUG - https://o151352.ingest.sentry.io:443 "POST /api/5288891/envelope/ HTTP/1.1" 200 2
2023-01-13 19:13:34,953 - root - DEBUG - Logging configured!
2023-01-13 19:13:34,955 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 10000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 2
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 4
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.3
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.3
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = trash
init_wandb.id = trash000
2023-01-13 19:13:34,961 - __main__ - INFO - Creating model...
2023-01-13 19:13:35,041 - __main__ - INFO - Using device: cpu
2023-01-13 19:13:35,553 - git.cmd - DEBUG - Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/Users/philippemartin/Documents/projets_IA/Drug Discovery/megan, universal_newlines=False, shell=None, istream=None)
2023-01-13 19:13:37,937 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2023-01-13 19:13:38,099 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 579
2023-01-13 19:13:38,121 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2023-01-13 19:13:38,271 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 339
2023-01-13 19:13:38,338 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/philippemartin/Documents/projets_IA/Drug Discovery/megan, universal_newlines=False, shell=None, istream=<valid stream>)
2023-01-13 19:13:39,314 - __main__ - INFO - Loading data...
2023-01-13 19:13:39,315 - __main__ - INFO - Training for maximum of 200 epochs...
2023-01-13 19:13:39,318 - __main__ - INFO - Loading data
2023-01-13 19:13:40,241 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-13 19:13:40,241 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-13 19:13:41,874 - matplotlib.pyplot - DEBUG - Loaded backend macosx version unknown.
2023-01-13 19:13:41,875 - matplotlib.pyplot - DEBUG - Loaded backend MacOSX version unknown.
2023-01-13 19:13:41,877 - matplotlib.pyplot - DEBUG - Loaded backend macosx version unknown.
2023-01-13 19:14:39,061 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): o151352.ingest.sentry.io:443
2023-01-13 19:14:39,150 - urllib3.connectionpool - DEBUG - https://o151352.ingest.sentry.io:443 "POST /api/5288891/envelope/ HTTP/1.1" 200 2
2023-01-17 21:50:02,647 - root - DEBUG - Logging configured!
2023-01-17 21:50:02,649 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 10000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 2
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 4
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.3
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.3
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = trash
init_wandb.id = trash000
2023-01-17 21:50:02,657 - __main__ - INFO - Creating model...
2023-01-17 21:50:02,751 - __main__ - INFO - Using device: cpu
2023-01-17 21:50:03,207 - git.cmd - DEBUG - Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/Users/philippemartin/Documents/projets_IA/Drug Discovery/megan, universal_newlines=False, shell=None, istream=None)
2023-01-17 21:50:05,676 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2023-01-17 21:50:06,145 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 579
2023-01-17 21:50:06,178 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2023-01-17 21:50:06,584 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 339
2023-01-17 21:50:06,657 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/philippemartin/Documents/projets_IA/Drug Discovery/megan, universal_newlines=False, shell=None, istream=<valid stream>)
2023-01-17 21:50:09,050 - __main__ - INFO - Loading data...
2023-01-17 21:50:09,051 - __main__ - INFO - Training for maximum of 200 epochs...
2023-01-17 21:50:09,054 - __main__ - INFO - Loading data
2023-01-17 21:50:10,005 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-17 21:50:10,006 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-17 21:50:10,957 - matplotlib.pyplot - DEBUG - Loaded backend macosx version unknown.
2023-01-17 21:50:10,958 - matplotlib.pyplot - DEBUG - Loaded backend MacOSX version unknown.
2023-01-17 21:50:10,960 - matplotlib.pyplot - DEBUG - Loaded backend macosx version unknown.
2023-01-17 21:51:08,128 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): o151352.ingest.sentry.io:443
2023-01-17 21:51:08,649 - urllib3.connectionpool - DEBUG - https://o151352.ingest.sentry.io:443 "POST /api/5288891/envelope/ HTTP/1.1" 200 2
2023-01-17 22:01:32,970 - root - DEBUG - Logging configured!
2023-01-17 22:01:32,972 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 10000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 2
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 4
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.3
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.3
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = trash
init_wandb.id = trash000
2023-01-17 22:01:32,979 - __main__ - INFO - Creating model...
2023-01-17 22:01:33,062 - __main__ - INFO - Using device: cpu
2023-01-17 22:01:33,581 - git.cmd - DEBUG - Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/Users/philippemartin/Documents/projets_IA/Drug Discovery/megan, universal_newlines=False, shell=None, istream=None)
2023-01-17 22:01:36,310 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2023-01-17 22:01:38,552 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 579
2023-01-17 22:01:38,571 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2023-01-17 22:01:40,082 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 339
2023-01-17 22:01:40,154 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/philippemartin/Documents/projets_IA/Drug Discovery/megan, universal_newlines=False, shell=None, istream=<valid stream>)
2023-01-17 22:01:47,145 - __main__ - INFO - Loading data...
2023-01-17 22:01:47,146 - __main__ - INFO - Training for maximum of 200 epochs...
2023-01-17 22:01:47,149 - __main__ - INFO - Loading data
2023-01-17 22:01:48,098 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-17 22:01:48,100 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-17 22:01:48,106 - __main__ - WARNING - Exception while running batch: module 'torch' has no attribute 'autocast'
2023-01-17 22:01:48,269 - matplotlib.pyplot - DEBUG - Loaded backend macosx version unknown.
2023-01-17 22:01:48,270 - matplotlib.pyplot - DEBUG - Loaded backend MacOSX version unknown.
2023-01-17 22:01:48,273 - matplotlib.pyplot - DEBUG - Loaded backend macosx version unknown.
2023-01-17 22:02:44,916 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): o151352.ingest.sentry.io:443
2023-01-17 22:02:46,900 - urllib3.connectionpool - DEBUG - https://o151352.ingest.sentry.io:443 "POST /api/5288891/envelope/ HTTP/1.1" 200 2
2023-01-17 22:07:40,812 - root - DEBUG - Logging configured!
2023-01-17 22:07:40,814 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 10000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 2
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 4
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.3
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.3
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = trash
init_wandb.id = trash000
2023-01-17 22:07:40,822 - __main__ - INFO - Creating model...
2023-01-17 22:07:40,919 - __main__ - INFO - Using device: cpu
2023-01-17 22:07:41,473 - git.cmd - DEBUG - Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/Users/philippemartin/Documents/projets_IA/Drug Discovery/megan, universal_newlines=False, shell=None, istream=None)
2023-01-17 22:07:44,070 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2023-01-17 22:07:44,477 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 579
2023-01-17 22:07:44,495 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2023-01-17 22:07:44,880 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 339
2023-01-17 22:07:44,948 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/philippemartin/Documents/projets_IA/Drug Discovery/megan, universal_newlines=False, shell=None, istream=<valid stream>)
2023-01-17 22:07:47,528 - __main__ - INFO - Loading data...
2023-01-17 22:07:47,528 - __main__ - INFO - Training for maximum of 200 epochs...
2023-01-17 22:07:47,531 - __main__ - INFO - Loading data
2023-01-17 22:07:48,477 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-17 22:07:48,477 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-17 22:07:48,483 - __main__ - WARNING - Exception while running batch: module 'torch.cuda' has no attribute 'amp'
2023-01-17 22:07:48,637 - matplotlib.pyplot - DEBUG - Loaded backend macosx version unknown.
2023-01-17 22:07:48,637 - matplotlib.pyplot - DEBUG - Loaded backend MacOSX version unknown.
2023-01-17 22:07:48,639 - matplotlib.pyplot - DEBUG - Loaded backend macosx version unknown.
2023-01-17 22:08:46,479 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): o151352.ingest.sentry.io:443
2023-01-17 22:08:46,866 - urllib3.connectionpool - DEBUG - https://o151352.ingest.sentry.io:443 "POST /api/5288891/envelope/ HTTP/1.1" 200 2
2023-01-17 22:10:20,410 - root - DEBUG - Logging configured!
2023-01-17 22:10:20,411 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 10000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 2
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 4
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.3
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.3
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = trash
init_wandb.id = trash000
2023-01-17 22:10:20,418 - __main__ - INFO - Creating model...
2023-01-17 22:10:20,509 - __main__ - INFO - Using device: cpu
2023-01-17 22:10:21,059 - git.cmd - DEBUG - Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/Users/philippemartin/Documents/projets_IA/Drug Discovery/megan, universal_newlines=False, shell=None, istream=None)
2023-01-17 22:10:23,999 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2023-01-17 22:10:24,408 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 579
2023-01-17 22:10:24,428 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2023-01-17 22:10:24,813 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 339
2023-01-17 22:10:24,871 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/philippemartin/Documents/projets_IA/Drug Discovery/megan, universal_newlines=False, shell=None, istream=<valid stream>)
2023-01-17 22:10:27,812 - __main__ - INFO - Loading data...
2023-01-17 22:10:27,813 - __main__ - INFO - Training for maximum of 200 epochs...
2023-01-17 22:10:27,816 - __main__ - INFO - Loading data
2023-01-17 22:10:28,818 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-17 22:10:28,818 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-17 22:10:28,825 - __main__ - WARNING - Exception while running batch: module 'torch' has no attribute 'cpu'
2023-01-17 22:10:29,034 - matplotlib.pyplot - DEBUG - Loaded backend macosx version unknown.
2023-01-17 22:10:29,035 - matplotlib.pyplot - DEBUG - Loaded backend MacOSX version unknown.
2023-01-17 22:10:29,040 - matplotlib.pyplot - DEBUG - Loaded backend macosx version unknown.
2023-01-17 22:11:26,871 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): o151352.ingest.sentry.io:443
2023-01-17 22:11:28,098 - urllib3.connectionpool - DEBUG - https://o151352.ingest.sentry.io:443 "POST /api/5288891/envelope/ HTTP/1.1" 200 2
2023-01-17 22:15:31,972 - root - DEBUG - Logging configured!
2023-01-17 22:15:31,973 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 10000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 2
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 4
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.3
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.3
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = trash
init_wandb.id = trash000
2023-01-17 22:15:31,980 - __main__ - INFO - Creating model...
2023-01-17 22:15:32,108 - __main__ - INFO - Using device: cpu
2023-01-17 22:15:32,621 - git.cmd - DEBUG - Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/Users/philippemartin/Documents/projets_IA/Drug Discovery/megan, universal_newlines=False, shell=None, istream=None)
2023-01-17 22:15:35,170 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2023-01-17 22:15:35,583 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 579
2023-01-17 22:15:35,596 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2023-01-17 22:15:35,997 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 339
2023-01-17 22:15:36,068 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/philippemartin/Documents/projets_IA/Drug Discovery/megan, universal_newlines=False, shell=None, istream=<valid stream>)
2023-01-17 22:15:38,809 - __main__ - INFO - Loading data...
2023-01-17 22:15:38,810 - __main__ - INFO - Training for maximum of 200 epochs...
2023-01-17 22:15:38,813 - __main__ - INFO - Loading data
2023-01-17 22:15:39,743 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-17 22:15:39,743 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-17 22:15:39,809 - __main__ - WARNING - Exception while running batch: Expected object of scalar type Float but got scalar type Half for argument #2 'mat2' in call to _th_mm
2023-01-17 22:15:39,952 - matplotlib.pyplot - DEBUG - Loaded backend macosx version unknown.
2023-01-17 22:15:39,952 - matplotlib.pyplot - DEBUG - Loaded backend MacOSX version unknown.
2023-01-17 22:15:39,954 - matplotlib.pyplot - DEBUG - Loaded backend macosx version unknown.
2023-01-17 22:18:46,252 - root - DEBUG - Logging configured!
2023-01-17 22:18:46,254 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 10000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 2
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 4
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.3
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.3
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = trash
init_wandb.id = trash000
2023-01-17 22:18:46,261 - __main__ - INFO - Creating model...
2023-01-17 22:18:46,396 - __main__ - INFO - Using device: cpu
2023-01-17 22:18:46,928 - git.cmd - DEBUG - Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/Users/philippemartin/Documents/projets_IA/Drug Discovery/megan, universal_newlines=False, shell=None, istream=None)
2023-01-17 22:18:49,666 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2023-01-17 22:18:50,102 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 579
2023-01-17 22:18:50,132 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2023-01-17 22:18:50,547 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 339
2023-01-17 22:18:50,623 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/philippemartin/Documents/projets_IA/Drug Discovery/megan, universal_newlines=False, shell=None, istream=<valid stream>)
2023-01-17 22:18:54,162 - __main__ - INFO - Loading data...
2023-01-17 22:18:54,162 - __main__ - INFO - Training for maximum of 200 epochs...
2023-01-17 22:18:54,166 - __main__ - INFO - Loading data
2023-01-17 22:18:55,130 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-17 22:18:55,131 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-17 22:18:55,172 - __main__ - WARNING - Exception while running batch: Expected object of scalar type Long but got scalar type Half for argument #3 'index' in call to _th_scatter_
2023-01-17 22:18:55,324 - matplotlib.pyplot - DEBUG - Loaded backend macosx version unknown.
2023-01-17 22:18:55,325 - matplotlib.pyplot - DEBUG - Loaded backend MacOSX version unknown.
2023-01-17 22:18:55,327 - matplotlib.pyplot - DEBUG - Loaded backend macosx version unknown.
2023-01-17 22:37:23,492 - root - DEBUG - Logging configured!
2023-01-17 22:37:23,494 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 10000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 2
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 4
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.3
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.3
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = trash
init_wandb.id = trash000
2023-01-17 22:37:23,502 - __main__ - INFO - Creating model...
2023-01-17 22:37:23,630 - __main__ - INFO - Using device: cpu
2023-01-17 22:37:24,133 - git.cmd - DEBUG - Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/Users/philippemartin/Documents/projets_IA/Drug Discovery/megan, universal_newlines=False, shell=None, istream=None)
2023-01-17 22:37:26,481 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2023-01-17 22:37:27,553 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 579
2023-01-17 22:37:27,579 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2023-01-17 22:37:29,054 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 339
2023-01-17 22:37:29,122 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/philippemartin/Documents/projets_IA/Drug Discovery/megan, universal_newlines=False, shell=None, istream=<valid stream>)
2023-01-17 22:37:33,889 - __main__ - INFO - Loading data...
2023-01-17 22:37:33,889 - __main__ - INFO - Training for maximum of 200 epochs...
2023-01-17 22:37:33,893 - __main__ - INFO - Loading data
2023-01-17 22:37:34,897 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-17 22:37:34,898 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-17 22:37:34,924 - __main__ - WARNING - Exception while running batch: 'builtin_function_or_method' object is not iterable
2023-01-17 22:37:35,092 - matplotlib.pyplot - DEBUG - Loaded backend macosx version unknown.
2023-01-17 22:37:35,092 - matplotlib.pyplot - DEBUG - Loaded backend MacOSX version unknown.
2023-01-17 22:37:35,094 - matplotlib.pyplot - DEBUG - Loaded backend macosx version unknown.
2023-01-17 22:38:32,805 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): o151352.ingest.sentry.io:443
2023-01-17 22:38:34,269 - urllib3.connectionpool - DEBUG - https://o151352.ingest.sentry.io:443 "POST /api/5288891/envelope/ HTTP/1.1" 200 2
2023-01-17 22:41:52,082 - root - DEBUG - Logging configured!
2023-01-17 22:41:52,083 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 10000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 2
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 4
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.3
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.3
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = trash
init_wandb.id = trash000
2023-01-17 22:41:52,089 - __main__ - INFO - Creating model...
2023-01-17 22:41:52,220 - __main__ - INFO - Using device: cpu
2023-01-17 22:41:52,733 - git.cmd - DEBUG - Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/Users/philippemartin/Documents/projets_IA/Drug Discovery/megan, universal_newlines=False, shell=None, istream=None)
2023-01-17 22:41:55,268 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2023-01-17 22:41:55,747 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 579
2023-01-17 22:41:55,769 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2023-01-17 22:41:56,190 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 339
2023-01-17 22:41:56,259 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/philippemartin/Documents/projets_IA/Drug Discovery/megan, universal_newlines=False, shell=None, istream=<valid stream>)
2023-01-17 22:42:01,511 - __main__ - INFO - Loading data...
2023-01-17 22:42:01,512 - __main__ - INFO - Training for maximum of 200 epochs...
2023-01-17 22:42:01,515 - __main__ - INFO - Loading data
2023-01-17 22:42:02,457 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-17 22:42:02,459 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-17 22:42:02,488 - __main__ - WARNING - Exception while running batch: Expected object of scalar type Long but got scalar type Half for argument #3 'index' in call to _th_scatter_
2023-01-17 22:42:02,689 - matplotlib.pyplot - DEBUG - Loaded backend macosx version unknown.
2023-01-17 22:42:02,690 - matplotlib.pyplot - DEBUG - Loaded backend MacOSX version unknown.
2023-01-17 22:42:02,693 - matplotlib.pyplot - DEBUG - Loaded backend macosx version unknown.
2023-01-17 22:42:59,759 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): o151352.ingest.sentry.io:443
2023-01-17 22:43:00,231 - urllib3.connectionpool - DEBUG - https://o151352.ingest.sentry.io:443 "POST /api/5288891/envelope/ HTTP/1.1" 200 2
2023-01-18 13:41:07,440 - root - DEBUG - Logging configured!
2023-01-18 13:41:07,442 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 10000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 2
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 4
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.3
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.3
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = trash
init_wandb.id = trash000
2023-01-18 13:41:07,448 - __main__ - INFO - Creating model...
2023-01-18 13:41:07,536 - __main__ - INFO - Using device: cpu
2023-01-18 13:41:07,537 - __main__ - INFO - Loading data...
2023-01-18 13:41:07,537 - __main__ - INFO - Training for maximum of 200 epochs...
2023-01-18 13:41:07,540 - __main__ - INFO - Loading data
2023-01-18 13:41:08,380 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-18 13:41:08,380 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-18 13:41:08,573 - matplotlib.pyplot - DEBUG - Loaded backend macosx version unknown.
2023-01-18 13:41:08,573 - matplotlib.pyplot - DEBUG - Loaded backend MacOSX version unknown.
2023-01-18 13:41:08,575 - matplotlib.pyplot - DEBUG - Loaded backend macosx version unknown.
2023-01-18 13:47:35,447 - root - DEBUG - Logging configured!
2023-01-18 13:47:35,448 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 10000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 2
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 4
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.3
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.3
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = trash
init_wandb.id = trash000
2023-01-18 13:47:35,454 - __main__ - INFO - Creating model...
2023-01-18 13:47:35,572 - __main__ - INFO - Using device: cpu
2023-01-18 13:47:35,572 - __main__ - INFO - Loading data...
2023-01-18 13:47:35,572 - __main__ - INFO - Training for maximum of 200 epochs...
2023-01-18 13:47:35,575 - __main__ - INFO - Loading data
2023-01-18 13:47:36,365 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-18 13:47:36,365 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-18 13:47:36,479 - matplotlib.pyplot - DEBUG - Loaded backend macosx version unknown.
2023-01-18 13:47:36,480 - matplotlib.pyplot - DEBUG - Loaded backend MacOSX version unknown.
2023-01-18 13:47:36,482 - matplotlib.pyplot - DEBUG - Loaded backend macosx version unknown.
2023-01-18 13:47:40,767 - __main__ - WARNING - Exception while running batch: Expected object of scalar type Long but got scalar type Half for argument #3 'index' in call to _th_scatter_
2023-01-18 13:48:46,763 - root - DEBUG - Logging configured!
2023-01-18 13:48:46,764 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 10000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 2
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 4
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.3
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.3
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = trash
init_wandb.id = trash000
2023-01-18 13:48:46,768 - __main__ - INFO - Creating model...
2023-01-18 13:48:46,895 - __main__ - INFO - Using device: cpu
2023-01-18 13:48:46,895 - __main__ - INFO - Loading data...
2023-01-18 13:48:46,896 - __main__ - INFO - Training for maximum of 200 epochs...
2023-01-18 13:48:46,898 - __main__ - INFO - Loading data
2023-01-18 13:48:47,774 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-18 13:48:47,774 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-18 13:48:47,890 - matplotlib.pyplot - DEBUG - Loaded backend macosx version unknown.
2023-01-18 13:48:47,890 - matplotlib.pyplot - DEBUG - Loaded backend MacOSX version unknown.
2023-01-18 13:48:47,893 - matplotlib.pyplot - DEBUG - Loaded backend macosx version unknown.
2023-01-18 13:49:13,728 - root - DEBUG - Logging configured!
2023-01-18 13:49:13,729 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 10000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 2
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 4
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.3
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.3
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = trash
init_wandb.id = trash000
2023-01-18 13:49:13,735 - __main__ - INFO - Creating model...
2023-01-18 13:49:13,853 - __main__ - INFO - Using device: cpu
2023-01-18 13:49:13,854 - __main__ - INFO - Loading data...
2023-01-18 13:49:13,854 - __main__ - INFO - Training for maximum of 200 epochs...
2023-01-18 13:49:13,857 - __main__ - INFO - Loading data
2023-01-18 13:49:14,634 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-18 13:49:14,635 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-18 13:49:14,748 - matplotlib.pyplot - DEBUG - Loaded backend macosx version unknown.
2023-01-18 13:49:14,748 - matplotlib.pyplot - DEBUG - Loaded backend MacOSX version unknown.
2023-01-18 13:49:14,750 - matplotlib.pyplot - DEBUG - Loaded backend macosx version unknown.
2023-01-18 13:49:16,629 - __main__ - WARNING - Exception while running batch: _th_scatter_ not supported on CPUType for Half
