2023-01-07 13:08:09,207 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 20000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 4
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 6
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.0
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.0
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = v2
init_wandb.id = megan0v2
2023-01-07 13:08:09,222 - __main__ - INFO - Creating model...
2023-01-07 13:08:10,459 - __main__ - INFO - Using device: cuda:0
2023-01-07 13:18:28,146 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 20000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 4
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 6
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.0
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.0
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = v2
init_wandb.id = megan1v2
2023-01-07 13:18:28,152 - __main__ - INFO - Creating model...
2023-01-07 13:18:29,377 - __main__ - INFO - Using device: cuda:0
2023-01-07 13:18:38,790 - __main__ - INFO - Loading data...
2023-01-07 13:18:38,790 - __main__ - INFO - Training for maximum of 200 epochs...
2023-01-07 13:18:38,791 - __main__ - INFO - Loading data
2023-01-07 13:18:39,648 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-07 13:18:39,649 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-07 13:19:00,761 - __main__ - WARNING - Exception while running batch: CUDA out of memory. Tried to allocate 222.00 MiB (GPU 0; 6.00 GiB total capacity; 5.24 GiB already allocated; 0 bytes free; 56.64 MiB cached)
2023-01-07 13:20:20,338 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 20000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 4
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 6
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.0
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.0
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = v2
init_wandb.id = megan1v2
2023-01-07 13:20:20,345 - __main__ - INFO - Creating model...
2023-01-07 13:20:21,566 - __main__ - INFO - Using device: cuda:0
2023-01-07 13:20:25,885 - __main__ - INFO - Loading data...
2023-01-07 13:20:25,886 - __main__ - INFO - Training for maximum of 200 epochs...
2023-01-07 13:20:25,887 - __main__ - INFO - Loading data
2023-01-07 13:20:26,733 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-07 13:20:26,734 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-07 13:20:46,837 - __main__ - WARNING - Exception while running batch: CUDA out of memory. Tried to allocate 222.00 MiB (GPU 0; 6.00 GiB total capacity; 5.24 GiB already allocated; 0 bytes free; 56.64 MiB cached)
2023-01-07 13:25:03,777 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 20000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 4
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 6
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.0
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.0
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = v2
init_wandb.id = megan1v2
2023-01-07 13:25:03,784 - __main__ - INFO - Creating model...
2023-01-07 13:25:04,999 - __main__ - INFO - Using device: cuda:0
2023-01-07 13:25:09,443 - __main__ - INFO - Loading data...
2023-01-07 13:25:09,444 - __main__ - INFO - Training for maximum of 200 epochs...
2023-01-07 13:25:09,445 - __main__ - INFO - Loading data
2023-01-07 13:25:10,290 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-07 13:25:10,291 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-07 13:25:30,217 - __main__ - WARNING - Exception while running batch: CUDA out of memory. Tried to allocate 222.00 MiB (GPU 0; 6.00 GiB total capacity; 5.24 GiB already allocated; 0 bytes free; 56.64 MiB cached)
2023-01-07 13:27:45,883 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 20000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 4
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 4
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.3
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.0
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = v2
init_wandb.id = megan1v2
2023-01-07 13:27:45,890 - __main__ - INFO - Creating model...
2023-01-07 13:27:47,093 - __main__ - INFO - Using device: cuda:0
2023-01-07 13:27:51,358 - __main__ - INFO - Loading data...
2023-01-07 13:27:51,359 - __main__ - INFO - Training for maximum of 200 epochs...
2023-01-07 13:27:51,360 - __main__ - INFO - Loading data
2023-01-07 13:27:52,219 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-07 13:27:52,219 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-07 13:28:10,327 - __main__ - WARNING - Exception while running batch: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 6.00 GiB total capacity; 5.27 GiB already allocated; 0 bytes free; 32.00 MiB cached)
2023-01-07 13:31:21,650 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 20000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 3
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 6
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.0
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = v2
init_wandb.id = megan1v2
2023-01-07 13:31:21,656 - __main__ - INFO - Creating model...
2023-01-07 13:31:22,882 - __main__ - INFO - Using device: cuda:0
2023-01-07 13:31:27,304 - __main__ - INFO - Loading data...
2023-01-07 13:31:27,305 - __main__ - INFO - Training for maximum of 200 epochs...
2023-01-07 13:31:27,306 - __main__ - INFO - Loading data
2023-01-07 13:31:28,164 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-07 13:31:28,165 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-07 13:31:45,892 - __main__ - WARNING - Exception while running batch: CUDA out of memory. Tried to allocate 166.00 MiB (GPU 0; 6.00 GiB total capacity; 5.16 GiB already allocated; 0 bytes free; 101.35 MiB cached)
2023-01-07 13:33:02,712 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 20000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 3
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 4
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.0
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = v2
init_wandb.id = megan1v2
2023-01-07 13:33:02,717 - __main__ - INFO - Creating model...
2023-01-07 13:33:03,925 - __main__ - INFO - Using device: cuda:0
2023-01-07 13:33:08,289 - __main__ - INFO - Loading data...
2023-01-07 13:33:08,290 - __main__ - INFO - Training for maximum of 200 epochs...
2023-01-07 13:33:08,291 - __main__ - INFO - Loading data
2023-01-07 13:33:09,139 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-07 13:33:09,140 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-07 13:33:36,064 - __main__ - WARNING - Exception while running batch: CUDA out of memory. Tried to allocate 126.00 MiB (GPU 0; 6.00 GiB total capacity; 4.55 GiB already allocated; 0 bytes free; 668.46 MiB cached)
2023-01-07 22:11:48,445 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 20000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 3
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 4
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.0
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = v2
init_wandb.id = megan1v2
2023-01-07 22:11:48,454 - __main__ - INFO - Creating model...
2023-01-07 22:11:50,207 - __main__ - INFO - Using device: cuda:0
2023-01-07 22:11:54,635 - __main__ - INFO - Loading data...
2023-01-07 22:11:54,635 - __main__ - INFO - Training for maximum of 200 epochs...
2023-01-07 22:11:54,636 - __main__ - INFO - Loading data
2023-01-07 22:11:55,492 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-07 22:11:55,493 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-07 22:12:22,277 - __main__ - WARNING - Exception while running batch: CUDA out of memory. Tried to allocate 126.00 MiB (GPU 0; 6.00 GiB total capacity; 4.55 GiB already allocated; 0 bytes free; 668.46 MiB cached)
2023-01-07 22:15:02,564 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 20000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 3
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 4
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.3
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.3
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = v2
init_wandb.id = megan1v2
2023-01-07 22:15:02,571 - __main__ - INFO - Creating model...
2023-01-07 22:15:03,762 - __main__ - INFO - Using device: cuda:0
2023-01-07 22:15:08,136 - __main__ - INFO - Loading data...
2023-01-07 22:15:08,136 - __main__ - INFO - Training for maximum of 200 epochs...
2023-01-07 22:15:08,137 - __main__ - INFO - Loading data
2023-01-07 22:15:08,981 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-07 22:15:08,981 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-07 22:15:35,494 - __main__ - WARNING - Exception while running batch: CUDA out of memory. Tried to allocate 126.00 MiB (GPU 0; 6.00 GiB total capacity; 4.74 GiB already allocated; 0 bytes free; 583.09 MiB cached)
2023-01-10 11:08:08,222 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 20000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 3
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 4
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.3
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.3
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = v2
init_wandb.id = megan1v2
2023-01-10 11:08:08,229 - __main__ - INFO - Creating model...
2023-01-10 11:08:09,996 - __main__ - INFO - Using device: cuda:0
2023-01-10 11:11:34,106 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 20000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 3
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 4
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.3
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.3
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = v2
init_wandb.id = megan1v2
2023-01-10 11:11:34,113 - __main__ - INFO - Creating model...
2023-01-10 11:11:35,315 - __main__ - INFO - Using device: cuda:0
2023-01-10 11:12:13,324 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 20000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 3
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 4
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.3
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.3
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = v2
init_wandb.id = megan1v2
2023-01-10 11:12:13,331 - __main__ - INFO - Creating model...
2023-01-10 11:12:14,526 - __main__ - INFO - Using device: cuda:0
2023-01-10 11:12:14,580 - src.utils.dispatch_utils - INFO - 38234.5 Kb
2023-01-10 11:12:20,718 - __main__ - INFO - Loading data...
2023-01-10 11:12:20,719 - __main__ - INFO - Training for maximum of 200 epochs...
2023-01-10 11:12:20,720 - __main__ - INFO - Loading data
2023-01-10 11:12:21,584 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-10 11:12:21,584 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-10 11:12:49,400 - __main__ - WARNING - Exception while running batch: CUDA out of memory. Tried to allocate 126.00 MiB (GPU 0; 6.00 GiB total capacity; 4.74 GiB already allocated; 0 bytes free; 583.09 MiB cached)
2023-01-10 11:25:09,959 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 20000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 3
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 4
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.3
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.3
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = v2
init_wandb.id = megan1v2
2023-01-10 11:25:09,965 - __main__ - INFO - Creating model...
2023-01-10 11:25:11,146 - __main__ - INFO - Using device: cuda:0
2023-01-10 11:25:11,197 - src.utils.dispatch_utils - INFO - 38234.5 Kb
2023-01-10 11:25:15,742 - __main__ - INFO - Loading data...
2023-01-10 11:25:15,742 - __main__ - INFO - Training for maximum of 200 epochs...
2023-01-10 11:25:15,743 - __main__ - INFO - Loading data
2023-01-10 11:25:16,581 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-10 11:25:16,582 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-10 11:25:43,600 - __main__ - WARNING - Exception while running batch: CUDA out of memory. Tried to allocate 126.00 MiB (GPU 0; 6.00 GiB total capacity; 4.74 GiB already allocated; 0 bytes free; 583.09 MiB cached)
2023-01-10 11:34:31,750 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 20000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 2
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 6
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.3
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.3
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = v2
init_wandb.id = megan1v2
2023-01-10 11:34:31,756 - __main__ - INFO - Creating model...
2023-01-10 11:34:32,971 - __main__ - INFO - Using device: cuda:0
2023-01-10 11:34:33,025 - src.utils.dispatch_utils - INFO - 50551.5 Kb
2023-01-10 11:34:37,447 - __main__ - INFO - Loading data...
2023-01-10 11:34:37,448 - __main__ - INFO - Training for maximum of 200 epochs...
2023-01-10 11:34:37,449 - __main__ - INFO - Loading data
2023-01-10 11:34:38,305 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-10 11:34:38,306 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-10 11:53:55,472 - __main__ - WARNING - Exception while running batch: CUDA out of memory. Tried to allocate 98.00 MiB (GPU 0; 6.00 GiB total capacity; 5.18 GiB already allocated; 0 bytes free; 125.09 MiB cached)
2023-01-10 12:00:13,912 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 20000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 2
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 4
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.3
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.3
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = v2
init_wandb.id = megan1v2
2023-01-10 12:00:13,919 - __main__ - INFO - Creating model...
2023-01-10 12:00:15,109 - __main__ - INFO - Using device: cuda:0
2023-01-10 12:00:15,163 - src.utils.dispatch_utils - INFO - 38234.5 Kb
2023-01-10 12:00:19,584 - __main__ - INFO - Loading data...
2023-01-10 12:00:19,585 - __main__ - INFO - Training for maximum of 200 epochs...
2023-01-10 12:00:19,586 - __main__ - INFO - Loading data
2023-01-10 12:00:20,433 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-10 12:00:20,434 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-10 12:17:09,451 - __main__ - WARNING - Exception while running batch: CUDA out of memory. Tried to allocate 98.00 MiB (GPU 0; 6.00 GiB total capacity; 5.17 GiB already allocated; 0 bytes free; 91.03 MiB cached)
2023-01-10 19:42:42,690 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 3
train_megan.train_samples_per_epoch = 1000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 2
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 4
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.3
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.3
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = trash
init_wandb.id = trash000
2023-01-10 19:42:42,696 - __main__ - INFO - Creating model...
2023-01-10 19:42:42,793 - __main__ - INFO - Using device: cpu
2023-01-10 19:44:45,886 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 3
train_megan.train_samples_per_epoch = 1000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 2
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 4
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.3
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.3
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = trash
init_wandb.id = trash000
2023-01-10 19:44:45,888 - __main__ - INFO - Creating model...
2023-01-10 19:44:46,024 - __main__ - INFO - Using device: cpu
2023-01-10 19:44:53,398 - __main__ - INFO - Loading data...
2023-01-10 19:44:53,399 - __main__ - INFO - Training for maximum of 3 epochs...
2023-01-10 19:44:53,400 - __main__ - INFO - Loading data
2023-01-10 19:44:54,326 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-10 19:44:54,327 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-10 19:56:36,646 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 3
train_megan.train_samples_per_epoch = 10000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 2
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 4
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.3
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.3
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = trash
init_wandb.id = trash000
2023-01-10 19:56:36,648 - __main__ - INFO - Creating model...
2023-01-10 19:56:36,719 - __main__ - INFO - Using device: cpu
2023-01-10 19:56:39,838 - __main__ - INFO - Loading data...
2023-01-10 19:56:39,839 - __main__ - INFO - Training for maximum of 3 epochs...
2023-01-10 19:56:39,840 - __main__ - INFO - Loading data
2023-01-10 19:56:40,644 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-10 19:56:40,644 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-10 20:14:53,501 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 20000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 2
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 4
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.3
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.3
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = trash
init_wandb.id = trash000
2023-01-10 20:14:53,507 - __main__ - INFO - Creating model...
2023-01-10 20:14:53,587 - __main__ - INFO - Using device: cpu
2023-01-10 20:14:57,954 - __main__ - INFO - Loading data...
2023-01-10 20:14:57,954 - __main__ - INFO - Training for maximum of 200 epochs...
2023-01-10 20:14:57,957 - __main__ - INFO - Loading data
2023-01-10 20:14:58,818 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-10 20:14:58,818 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-13 15:43:49,124 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 20000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 2
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 4
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.3
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.3
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = trash
init_wandb.id = trash000
2023-01-13 15:49:02,617 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 10000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 2
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 4
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.3
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.3
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = trash
init_wandb.id = trash000
2023-01-13 15:54:55,230 - __main__ - INFO - Creating model...
2023-01-13 15:56:55,134 - __main__ - INFO - Using device: cpu
2023-01-13 15:57:02,918 - __main__ - INFO - Loading data...
2023-01-13 15:57:02,919 - __main__ - INFO - Training for maximum of 200 epochs...
2023-01-13 15:57:02,922 - __main__ - INFO - Loading data
2023-01-13 16:09:31,538 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-13 16:09:31,539 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-13 16:37:02,810 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 10000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 2
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 4
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.3
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.3
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = trash
init_wandb.id = trash000
2023-01-13 16:37:05,735 - __main__ - INFO - Creating model...
2023-01-13 16:37:08,027 - __main__ - INFO - Using device: cpu
2023-01-13 16:37:13,844 - __main__ - INFO - Loading data...
2023-01-13 16:37:13,844 - __main__ - INFO - Training for maximum of 200 epochs...
2023-01-13 16:37:13,849 - __main__ - INFO - Loading data
2023-01-13 16:57:48,287 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-13 16:57:48,288 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-13 17:57:24,546 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 10000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 2
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 4
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.3
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.3
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = trash
init_wandb.id = trash000
2023-01-13 17:57:24,553 - __main__ - INFO - Creating model...
2023-01-13 17:57:24,634 - __main__ - INFO - Using device: cpu
2023-01-13 17:57:29,109 - __main__ - INFO - Loading data...
2023-01-13 17:57:29,110 - __main__ - INFO - Training for maximum of 200 epochs...
2023-01-13 17:57:29,113 - __main__ - INFO - Loading data
2023-01-13 17:57:30,060 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-13 17:57:30,061 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-13 18:18:24,473 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 20000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 2
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 4
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.3
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.3
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = trash
init_wandb.id = trash000
2023-01-13 18:18:24,478 - __main__ - INFO - Creating model...
2023-01-13 18:18:24,561 - __main__ - INFO - Using device: cpu
2023-01-13 18:18:30,149 - __main__ - INFO - Loading data...
2023-01-13 18:18:30,150 - __main__ - INFO - Training for maximum of 200 epochs...
2023-01-13 18:18:30,151 - __main__ - INFO - Loading data
2023-01-13 18:18:31,073 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-13 18:18:31,074 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-13 19:13:34,955 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 10000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 2
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 4
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.3
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.3
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = trash
init_wandb.id = trash000
2023-01-13 19:13:34,961 - __main__ - INFO - Creating model...
2023-01-13 19:13:35,041 - __main__ - INFO - Using device: cpu
2023-01-13 19:13:39,314 - __main__ - INFO - Loading data...
2023-01-13 19:13:39,315 - __main__ - INFO - Training for maximum of 200 epochs...
2023-01-13 19:13:39,318 - __main__ - INFO - Loading data
2023-01-13 19:13:40,241 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-13 19:13:40,241 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-17 21:50:02,649 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 10000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 2
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 4
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.3
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.3
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = trash
init_wandb.id = trash000
2023-01-17 21:50:02,657 - __main__ - INFO - Creating model...
2023-01-17 21:50:02,751 - __main__ - INFO - Using device: cpu
2023-01-17 21:50:09,050 - __main__ - INFO - Loading data...
2023-01-17 21:50:09,051 - __main__ - INFO - Training for maximum of 200 epochs...
2023-01-17 21:50:09,054 - __main__ - INFO - Loading data
2023-01-17 21:50:10,005 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-17 21:50:10,006 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-17 22:01:32,972 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 10000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 2
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 4
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.3
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.3
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = trash
init_wandb.id = trash000
2023-01-17 22:01:32,979 - __main__ - INFO - Creating model...
2023-01-17 22:01:33,062 - __main__ - INFO - Using device: cpu
2023-01-17 22:01:47,145 - __main__ - INFO - Loading data...
2023-01-17 22:01:47,146 - __main__ - INFO - Training for maximum of 200 epochs...
2023-01-17 22:01:47,149 - __main__ - INFO - Loading data
2023-01-17 22:01:48,098 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-17 22:01:48,100 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-17 22:01:48,106 - __main__ - WARNING - Exception while running batch: module 'torch' has no attribute 'autocast'
2023-01-17 22:07:40,814 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 10000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 2
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 4
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.3
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.3
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = trash
init_wandb.id = trash000
2023-01-17 22:07:40,822 - __main__ - INFO - Creating model...
2023-01-17 22:07:40,919 - __main__ - INFO - Using device: cpu
2023-01-17 22:07:47,528 - __main__ - INFO - Loading data...
2023-01-17 22:07:47,528 - __main__ - INFO - Training for maximum of 200 epochs...
2023-01-17 22:07:47,531 - __main__ - INFO - Loading data
2023-01-17 22:07:48,477 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-17 22:07:48,477 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-17 22:07:48,483 - __main__ - WARNING - Exception while running batch: module 'torch.cuda' has no attribute 'amp'
2023-01-17 22:10:20,411 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 10000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 2
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 4
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.3
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.3
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = trash
init_wandb.id = trash000
2023-01-17 22:10:20,418 - __main__ - INFO - Creating model...
2023-01-17 22:10:20,509 - __main__ - INFO - Using device: cpu
2023-01-17 22:10:27,812 - __main__ - INFO - Loading data...
2023-01-17 22:10:27,813 - __main__ - INFO - Training for maximum of 200 epochs...
2023-01-17 22:10:27,816 - __main__ - INFO - Loading data
2023-01-17 22:10:28,818 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-17 22:10:28,818 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-17 22:10:28,825 - __main__ - WARNING - Exception while running batch: module 'torch' has no attribute 'cpu'
2023-01-17 22:15:31,973 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 10000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 2
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 4
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.3
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.3
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = trash
init_wandb.id = trash000
2023-01-17 22:15:31,980 - __main__ - INFO - Creating model...
2023-01-17 22:15:32,108 - __main__ - INFO - Using device: cpu
2023-01-17 22:15:38,809 - __main__ - INFO - Loading data...
2023-01-17 22:15:38,810 - __main__ - INFO - Training for maximum of 200 epochs...
2023-01-17 22:15:38,813 - __main__ - INFO - Loading data
2023-01-17 22:15:39,743 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-17 22:15:39,743 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-17 22:15:39,809 - __main__ - WARNING - Exception while running batch: Expected object of scalar type Float but got scalar type Half for argument #2 'mat2' in call to _th_mm
2023-01-17 22:18:46,254 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 10000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 2
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 4
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.3
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.3
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = trash
init_wandb.id = trash000
2023-01-17 22:18:46,261 - __main__ - INFO - Creating model...
2023-01-17 22:18:46,396 - __main__ - INFO - Using device: cpu
2023-01-17 22:18:54,162 - __main__ - INFO - Loading data...
2023-01-17 22:18:54,162 - __main__ - INFO - Training for maximum of 200 epochs...
2023-01-17 22:18:54,166 - __main__ - INFO - Loading data
2023-01-17 22:18:55,130 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-17 22:18:55,131 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-17 22:18:55,172 - __main__ - WARNING - Exception while running batch: Expected object of scalar type Long but got scalar type Half for argument #3 'index' in call to _th_scatter_
2023-01-17 22:37:23,494 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 10000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 2
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 4
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.3
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.3
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = trash
init_wandb.id = trash000
2023-01-17 22:37:23,502 - __main__ - INFO - Creating model...
2023-01-17 22:37:23,630 - __main__ - INFO - Using device: cpu
2023-01-17 22:37:33,889 - __main__ - INFO - Loading data...
2023-01-17 22:37:33,889 - __main__ - INFO - Training for maximum of 200 epochs...
2023-01-17 22:37:33,893 - __main__ - INFO - Loading data
2023-01-17 22:37:34,897 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-17 22:37:34,898 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-17 22:37:34,924 - __main__ - WARNING - Exception while running batch: 'builtin_function_or_method' object is not iterable
2023-01-17 22:41:52,083 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 10000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 2
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 4
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.3
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.3
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = trash
init_wandb.id = trash000
2023-01-17 22:41:52,089 - __main__ - INFO - Creating model...
2023-01-17 22:41:52,220 - __main__ - INFO - Using device: cpu
2023-01-17 22:42:01,511 - __main__ - INFO - Loading data...
2023-01-17 22:42:01,512 - __main__ - INFO - Training for maximum of 200 epochs...
2023-01-17 22:42:01,515 - __main__ - INFO - Loading data
2023-01-17 22:42:02,457 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-17 22:42:02,459 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-17 22:42:02,488 - __main__ - WARNING - Exception while running batch: Expected object of scalar type Long but got scalar type Half for argument #3 'index' in call to _th_scatter_
2023-01-18 13:41:07,442 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 10000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 2
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 4
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.3
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.3
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = trash
init_wandb.id = trash000
2023-01-18 13:41:07,448 - __main__ - INFO - Creating model...
2023-01-18 13:41:07,536 - __main__ - INFO - Using device: cpu
2023-01-18 13:41:07,537 - __main__ - INFO - Loading data...
2023-01-18 13:41:07,537 - __main__ - INFO - Training for maximum of 200 epochs...
2023-01-18 13:41:07,540 - __main__ - INFO - Loading data
2023-01-18 13:41:08,380 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-18 13:41:08,380 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-18 13:47:35,448 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 10000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 2
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 4
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.3
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.3
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = trash
init_wandb.id = trash000
2023-01-18 13:47:35,454 - __main__ - INFO - Creating model...
2023-01-18 13:47:35,572 - __main__ - INFO - Using device: cpu
2023-01-18 13:47:35,572 - __main__ - INFO - Loading data...
2023-01-18 13:47:35,572 - __main__ - INFO - Training for maximum of 200 epochs...
2023-01-18 13:47:35,575 - __main__ - INFO - Loading data
2023-01-18 13:47:36,365 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-18 13:47:36,365 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-18 13:47:40,767 - __main__ - WARNING - Exception while running batch: Expected object of scalar type Long but got scalar type Half for argument #3 'index' in call to _th_scatter_
2023-01-18 13:48:46,764 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 10000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 2
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 4
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.3
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.3
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = trash
init_wandb.id = trash000
2023-01-18 13:48:46,768 - __main__ - INFO - Creating model...
2023-01-18 13:48:46,895 - __main__ - INFO - Using device: cpu
2023-01-18 13:48:46,895 - __main__ - INFO - Loading data...
2023-01-18 13:48:46,896 - __main__ - INFO - Training for maximum of 200 epochs...
2023-01-18 13:48:46,898 - __main__ - INFO - Loading data
2023-01-18 13:48:47,774 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-18 13:48:47,774 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-18 13:49:13,729 - src.utils.dispatch_utils - INFO - gin-bound config values:
get_dataset.dataset_key = uspto_50k
train_megan.featurizer_key = megan_16_bfs_randat
train_megan.max_n_epochs = 200
train_megan.train_samples_per_epoch = 10000
train_megan.valid_samples_per_epoch = 5000
train_megan.batch_size = 2
train_megan.learning_rate = 0.0001
train_megan.gen_lr_factor = 0.05
train_megan.gen_lr_patience = 6
train_megan.early_stopping = 16
train_megan.start_epoch = 0
train_megan.megan_warmup_epochs = 1
Megan.reaction_type_given = False
Megan.bond_emb_dim = 32
Megan.hidden_dim = 1024
Megan.stateful = True
Megan.n_reaction_types = 10
Megan.reaction_type_emb_dim = 16
Megan.atom_feature_keys = ['is_supernode', 'atomic_num', 'formal_charge', 'chiral_tag', 'num_explicit_hs', 'is_aromatic']
Megan.bond_feature_keys = ['bond_type', 'bond_stereo']
MeganEncoder.n_encoder_conv = 4
MeganEncoder.enc_residual = True
MeganEncoder.enc_dropout = 0.3
MeganDecoder.n_decoder_conv = 2
MeganDecoder.dec_residual = True
MeganDecoder.n_fc = 2
MeganDecoder.atom_fc_hidden_dim = 128
MeganDecoder.bond_fc_hidden_dim = 128
MeganDecoder.bond_atom_dim = 128
MeganDecoder.dec_dropout = 0.3
MultiHeadGraphConvLayer.att_heads = 8
MultiHeadGraphConvLayer.att_dim = 128
MultiHeadGraphConvLayer.v2 = True
init_wandb.project = megan
init_wandb.name = trash
init_wandb.id = trash000
2023-01-18 13:49:13,735 - __main__ - INFO - Creating model...
2023-01-18 13:49:13,853 - __main__ - INFO - Using device: cpu
2023-01-18 13:49:13,854 - __main__ - INFO - Loading data...
2023-01-18 13:49:13,854 - __main__ - INFO - Training for maximum of 200 epochs...
2023-01-18 13:49:13,857 - __main__ - INFO - Loading data
2023-01-18 13:49:14,634 - __main__ - INFO - Training on chunk of 39934 training samples and 4992 valid samples
2023-01-18 13:49:14,635 - __main__ - INFO - Starting training on epoch 1 with Learning Rate=0.0 (1 warmup epochs)
2023-01-18 13:49:16,629 - __main__ - WARNING - Exception while running batch: _th_scatter_ not supported on CPUType for Half
